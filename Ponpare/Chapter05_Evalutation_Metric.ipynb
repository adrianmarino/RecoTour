{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 5\n",
    "\n",
    "In this chapter I will introduce the Mean Average Precision (MAP). In addition, I will try to answer the question *\"What is the worst we could do?\"* by computing the MAP@10 for random recommendations. \n",
    "\n",
    "### 5. 1 Evaluation Metric\n",
    "\n",
    "In the kaggle competition they ask us to evaluate our recommendations in terms of [Mean Average Precision](https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval) at 10 recommendations (MAP@10). \n",
    "\n",
    "The Average Precision (AP) is measured as (from wikipedia):\n",
    "\n",
    "$$\\text{AP} = \\frac{\\sum_{k=1}^{n} (P(k) \\times rel(k))}{\\text{number of relevant documents}}$$\n",
    "\n",
    "where $k$ is the rank in the sequence of retrieved documents, $n$ is the number of retrieved documents, $P(k)$ is the precision at cut-off $k$ in the list and $rel(k)$ is an indicator function equaling 1 if the item at rank $k$ is a relevant document, zero otherwise. Let's illustrate this with one example. Let's say that a user has interacted with 5 items, that will denote with numbers:\n",
    "\n",
    "```\n",
    "actual_items = [3, 7, 4, 2, 5]\n",
    "```\n",
    "\n",
    "Now let's say that our algorithm, out of all of the items in stock recommends the following 10, ranked based on some score designed to represent the likes of that customer:\n",
    "\n",
    "```\n",
    "recommended_items = [12, 7, 53, 90, 3, 23, 14, 37, 18, 67]\n",
    "```\n",
    "\n",
    "Then the MAP@10 would read as follow: our first recommendation fails (since 12 is not among the actual items). The second recommendation is a \"hit\". In other words, by the time we make two recommendations we got 1 right, so we add $1/2$. Our third recommendation is again, a bad one, as it is the forth. The fifth one however is another hit, so we add $2/5$. From there in advance we don't get any more hits. Therefore, the AP@10 is:\n",
    "\n",
    "$$ \\text{AP@10} = \\frac{0.5 + 0.4}{5} = 0.18$$\n",
    "\n",
    "The MAP@10 is nothing more than the average of all recommendations we make for all the users. In python, AP and MAP are implemented as (**credit goes [here](https://github.com/benhamner/Metrics/tree/master/Python/ml_metrics)**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted\n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if our example is alright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_items = [3, 7, 4, 2, 5]\n",
    "actual_items = [str(i) for i in actual_items]\n",
    "recommended_items = [12, 7, 53, 90, 3, 23, 14, 37, 18, 67]\n",
    "recommended_items = [str(i) for i in recommended_items]\n",
    "\n",
    "apk(actual_items, recommended_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my working directory I have included a module called `recutils` where I place all custome submodules that I will use during for the different examples. There you can find a `average_precision.py` with the code in the previous cell.\n",
    "\n",
    "If you want to learn more about Information Retrieval Metrics, please, visit [this repo](https://gist.github.com/bwhite/3726239) and the references therein. In the future I aim to include a version on [Normalize Discount Cumulative Gain](https://en.wikipedia.org/wiki/Discounted_cumulative_gain) (NDCG) where the relevance scale will be based on a meassure of interest of users in items. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Random recommendations\n",
    "\n",
    "One would hope that any algorithm, complex or not, performs better than just random recommendations. I would say that if the results of your algorithmic-based recommendations are similar to those of random recommendation, is almost certain that there is something wrong in your data. Maybe you made a mistake during feature engineering or the features you use don't mean a thing. \n",
    "\n",
    "In any case, let's see what is the MAP@10 for our dataset, when we use random recommendations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from recutils.average_precision import mapk\n",
    "\n",
    "inp_dir = \"./datasets/Ponpare/data_processed/\"\n",
    "train_dir = \"train\"\n",
    "valid_dir = \"valid\"\n",
    "\n",
    "# load train users dataframe\n",
    "df_user_train_feat = pd.read_pickle(os.path.join(inp_dir, 'train', 'df_users_train_feat.p'))\n",
    "train_users = df_user_train_feat.user_id_hash.unique()\n",
    "\n",
    "# validation coupons\n",
    "df_coupons_valid_feat = pd.read_pickle(os.path.join(inp_dir, 'valid', 'df_coupons_valid_feat.p'))\n",
    "\n",
    "# validation activities\n",
    "df_purchases_valid = pd.read_pickle(os.path.join(inp_dir, 'valid', 'df_purchases_valid.p'))\n",
    "df_visits_valid = pd.read_pickle(os.path.join(inp_dir, 'valid', 'df_visits_valid.p'))\n",
    "df_visits_valid.rename(index=str, columns={'view_coupon_id_hash': 'coupon_id_hash'}, inplace=True)\n",
    "\n",
    "# subset users that were seeing in training\n",
    "df_vva = df_visits_valid[df_visits_valid.user_id_hash.isin(train_users)]\n",
    "df_pva = df_purchases_valid[df_purchases_valid.user_id_hash.isin(train_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>user_id_hash</th>\n",
       "      <th>pref_name_cat</th>\n",
       "      <th>sex_id_cat</th>\n",
       "      <th>catalog_price_mean</th>\n",
       "      <th>catalog_price_median</th>\n",
       "      <th>catalog_price_min</th>\n",
       "      <th>catalog_price_max</th>\n",
       "      <th>discount_price_mean</th>\n",
       "      <th>discount_price_median</th>\n",
       "      <th>...</th>\n",
       "      <th>purchaseid_hash_count</th>\n",
       "      <th>coupon_id_hash_nunique</th>\n",
       "      <th>item_count_sum</th>\n",
       "      <th>small_area_name_nunique</th>\n",
       "      <th>day_of_week_nunique</th>\n",
       "      <th>median_time_diff</th>\n",
       "      <th>top1_small_area_name_cat</th>\n",
       "      <th>top2_small_area_name_cat</th>\n",
       "      <th>top1_dayofweek_cat</th>\n",
       "      <th>top2_dayofweek_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>d9dca3cb44bab12ba313eaa681f663eb</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>7200.0</td>\n",
       "      <td>7200.0</td>\n",
       "      <td>7200.0</td>\n",
       "      <td>1575.000000</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>560574a339f1b25e57b0221e486907ed</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3619.133333</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>1308.666667</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>e66ae91b978b3229f8fd858c80615b73</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2535.000000</td>\n",
       "      <td>2535.0</td>\n",
       "      <td>2535.0</td>\n",
       "      <td>2535.0</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>43fc18f32eafb05713ec02935e2c2825</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>500.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>dc6df8aa860f8db0d710ce9d4839840f</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8426.909091</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>37800.0</td>\n",
       "      <td>4198.181818</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22619</th>\n",
       "      <td>24</td>\n",
       "      <td>2f0a2f36a9f63b6ba2fa3a7e53bef906</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22620</th>\n",
       "      <td>41</td>\n",
       "      <td>6ae7811a9c7c58546d6a1567ab098c21</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1632.200000</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>656.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>42.5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22621</th>\n",
       "      <td>35</td>\n",
       "      <td>a417308c6a79ae0d86976401ec2e3b04</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22622</th>\n",
       "      <td>59</td>\n",
       "      <td>4937ec1c86e71d901c4ccc0357cff0b1</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>5400.000000</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>2460.000000</td>\n",
       "      <td>2460.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22623</th>\n",
       "      <td>38</td>\n",
       "      <td>280f0cedda5c4b171ee6245889659571</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4510.935484</td>\n",
       "      <td>2520.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>23100.0</td>\n",
       "      <td>1406.064516</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22624 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age                      user_id_hash  pref_name_cat  sex_id_cat  \\\n",
       "0       25  d9dca3cb44bab12ba313eaa681f663eb             47           0   \n",
       "1       34  560574a339f1b25e57b0221e486907ed              2           0   \n",
       "2       41  e66ae91b978b3229f8fd858c80615b73              4           1   \n",
       "3       25  43fc18f32eafb05713ec02935e2c2825             47           1   \n",
       "4       62  dc6df8aa860f8db0d710ce9d4839840f              5           1   \n",
       "...    ...                               ...            ...         ...   \n",
       "22619   24  2f0a2f36a9f63b6ba2fa3a7e53bef906             47           0   \n",
       "22620   41  6ae7811a9c7c58546d6a1567ab098c21              3           1   \n",
       "22621   35  a417308c6a79ae0d86976401ec2e3b04             47           0   \n",
       "22622   59  4937ec1c86e71d901c4ccc0357cff0b1             47           0   \n",
       "22623   38  280f0cedda5c4b171ee6245889659571              0           0   \n",
       "\n",
       "       catalog_price_mean  catalog_price_median  catalog_price_min  \\\n",
       "0             7200.000000                7200.0             7200.0   \n",
       "1             3619.133333                3000.0              320.0   \n",
       "2             2535.000000                2535.0             2535.0   \n",
       "3              500.750000                   1.0                1.0   \n",
       "4             8426.909091                4500.0              750.0   \n",
       "...                   ...                   ...                ...   \n",
       "22619        10000.000000               10000.0            10000.0   \n",
       "22620         1632.200000                1500.0                1.0   \n",
       "22621         2000.000000                2000.0             2000.0   \n",
       "22622         5400.000000                5400.0             5400.0   \n",
       "22623         4510.935484                2520.0              500.0   \n",
       "\n",
       "       catalog_price_max  discount_price_mean  discount_price_median  ...  \\\n",
       "0                 7200.0          1575.000000                 1575.0  ...   \n",
       "1                12000.0          1308.666667                 1000.0  ...   \n",
       "2                 2535.0          1500.000000                 1500.0  ...   \n",
       "3                 2000.0           250.000000                    0.0  ...   \n",
       "4                37800.0          4198.181818                 2250.0  ...   \n",
       "...                  ...                  ...                    ...  ...   \n",
       "22619            10000.0          5000.000000                 5000.0  ...   \n",
       "22620             4000.0           656.000000                  100.0  ...   \n",
       "22621             2000.0          1000.000000                 1000.0  ...   \n",
       "22622             5400.0          2460.000000                 2460.0  ...   \n",
       "22623            23100.0          1406.064516                 1100.0  ...   \n",
       "\n",
       "       purchaseid_hash_count  coupon_id_hash_nunique  item_count_sum  \\\n",
       "0                        1.0                     1.0             1.0   \n",
       "1                       15.0                    11.0            19.0   \n",
       "2                        1.0                     1.0             1.0   \n",
       "3                        4.0                     4.0             4.0   \n",
       "4                       22.0                    17.0            36.0   \n",
       "...                      ...                     ...             ...   \n",
       "22619                    1.0                     1.0             2.0   \n",
       "22620                    5.0                     5.0             5.0   \n",
       "22621                    1.0                     1.0             1.0   \n",
       "22622                    1.0                     1.0             2.0   \n",
       "22623                   31.0                    29.0            40.0   \n",
       "\n",
       "       small_area_name_nunique  day_of_week_nunique  median_time_diff  \\\n",
       "0                          1.0                  1.0               0.0   \n",
       "1                          4.0                  7.0              15.5   \n",
       "2                          1.0                  1.0               0.0   \n",
       "3                          2.0                  3.0              48.0   \n",
       "4                          9.0                  7.0               5.0   \n",
       "...                        ...                  ...               ...   \n",
       "22619                      1.0                  1.0               0.0   \n",
       "22620                      3.0                  4.0              42.5   \n",
       "22621                      1.0                  1.0               0.0   \n",
       "22622                      1.0                  1.0               0.0   \n",
       "22623                      8.0                  6.0               5.0   \n",
       "\n",
       "       top1_small_area_name_cat  top2_small_area_name_cat  top1_dayofweek_cat  \\\n",
       "0                            28                        28                   2   \n",
       "1                             4                        12                   5   \n",
       "2                             6                         6                   4   \n",
       "3                             2                        33                   0   \n",
       "4                             7                        15                   1   \n",
       "...                         ...                       ...                 ...   \n",
       "22619                        23                        23                   1   \n",
       "22620                         2                         5                   1   \n",
       "22621                        12                        12                   3   \n",
       "22622                        15                        15                   6   \n",
       "22623                         5                         2                   2   \n",
       "\n",
       "       top2_dayofweek_cat  \n",
       "0                       2  \n",
       "1                       3  \n",
       "2                       4  \n",
       "3                       2  \n",
       "4                       3  \n",
       "...                   ...  \n",
       "22619                   1  \n",
       "22620                   5  \n",
       "22621                   3  \n",
       "22622                   6  \n",
       "22623                   1  \n",
       "\n",
       "[22624 rows x 63 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user_train_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that here we will consider \"hits\" all interactions, whether purchases or visits. In the real world a more thorough analysis on this decision would be required (if not mandatory). For example, it is possible that when computing the MAP we want to add a weight to purchase-related hits that is higher than that of visits. \n",
    "\n",
    "Also, if you are a data scientist/analyst/ML engineer/etc building a recommendation algorithm in your company one would hope that you are familiar with the product that you are building the algorithm for. This knowledge might give you information on what to do with different types of interactions. \n",
    "\n",
    "For example, let's say we are building a recommendation algorithm for an online retail company. A user visits an item page once and spend less than $X$ seconds on the page (for example less than 5 seconds). Very likely this is an indication that the user did not like that item. However, if the user visits the item more than once or spends more than $X$ seconds on the item page is probably an indicator of some interest. All this should be considered when implementing your algorithm. \n",
    "\n",
    "Throughout the notebooks here, purchases and visits will be considered equally when computing the MAP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_hash</th>\n",
       "      <th>coupon_id_hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000cc06982785a19e2a2fdb40b1c9d59</td>\n",
       "      <td>[68b8f4ff1151b51f864764cab41a30b5, 977a7c4963a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002ae30377cd30f65652e52618e8b2d6</td>\n",
       "      <td>[1ae11153f2bfacec6ab5450d01453c4d, 404d7f06930...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002b08971471e6083dd716f6c3bb6572</td>\n",
       "      <td>[fed386703b0295119cadda40b20efcba, bd336887b48...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003a7b4941222b7e507fdc9e95de2cc1</td>\n",
       "      <td>[4bb514d6a036c3caba31d4b62f873cd7, b2a128a9175...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00441c9b51cfe60b82bdf7a20ad79fc8</td>\n",
       "      <td>[d7fb5915505943b2c7a7f5c1c550bb25, 9beb2e8ddc1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       user_id_hash  \\\n",
       "0  000cc06982785a19e2a2fdb40b1c9d59   \n",
       "1  002ae30377cd30f65652e52618e8b2d6   \n",
       "2  002b08971471e6083dd716f6c3bb6572   \n",
       "3  003a7b4941222b7e507fdc9e95de2cc1   \n",
       "4  00441c9b51cfe60b82bdf7a20ad79fc8   \n",
       "\n",
       "                                      coupon_id_hash  \n",
       "0  [68b8f4ff1151b51f864764cab41a30b5, 977a7c4963a...  \n",
       "1  [1ae11153f2bfacec6ab5450d01453c4d, 404d7f06930...  \n",
       "2  [fed386703b0295119cadda40b20efcba, bd336887b48...  \n",
       "3  [4bb514d6a036c3caba31d4b62f873cd7, b2a128a9175...  \n",
       "4  [d7fb5915505943b2c7a7f5c1c550bb25, 9beb2e8ddc1...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_cols = ['user_id_hash', 'coupon_id_hash']\n",
    "df_interactions_valid = pd.concat([df_pva[id_cols], df_vva[id_cols]], ignore_index=True)\n",
    "df_interactions_valid = (df_interactions_valid.groupby('user_id_hash')\n",
    "    .agg({'coupon_id_hash': 'unique'})\n",
    "    .reset_index())\n",
    "\n",
    "df_interactions_valid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's discuss an additional consideration. For this particular section it does not matter much, but in moving forward is good to at least mention it. There are some users that during the validation period did not interact with any of the validation coupons. This means that it does not matter how I rank validation coupons for these users, the AP is always going to be 0. We could either remove or keep those users, it does not matter as long as ***all algorithm comparisons*** are made with the same set of users. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fed386703b0295119cadda40b20efcba',\n",
       "       'bd336887b48211fdfffefa487a3f9825',\n",
       "       'b2a128a9175ce0b906f522136861c253',\n",
       "       '61b14e823046233811b066724ded6ec6'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_valid_dict = pd.Series(\n",
    "    df_interactions_valid.coupon_id_hash.values,\n",
    "    index=df_interactions_valid.user_id_hash\n",
    ").to_dict()\n",
    "valid_coupon_ids = df_coupons_valid_feat.coupon_id_hash.values\n",
    "\n",
    "# let's keep users that during the validation period, interacted with at least one validation coupon\n",
    "keep_users = []\n",
    "for user, coupons in tmp_valid_dict.items():\n",
    "    if np.intersect1d(valid_coupon_ids, coupons).size !=0:\n",
    "        keep_users.append(user)\n",
    "\n",
    "# out of 6924 users seen during validation, 6071 interacted with at least one validation coupon.\n",
    "interactions_valid_dict = {k:v for k,v in tmp_valid_dict.items() if k in keep_users}\n",
    "\n",
    "# for each user this dictionary contains the coupon_hash_id for the validation coupons \n",
    "# that that user interacted with\n",
    "interactions_valid_dict['002b08971471e6083dd716f6c3bb6572']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's then recommend at random and see which MAP we obtain. We run the loop a few times so we can average over a few random recommendation MAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008825646142715582\n"
     ]
    }
   ],
   "source": [
    "mapk_l = []\n",
    "\n",
    "for _ in range(10):\n",
    "    coupon_id_rn = valid_coupon_ids.copy()\n",
    "    recomendations_dict = {}\n",
    "    for user, _  in interactions_valid_dict.items():\n",
    "        np.random.shuffle(coupon_id_rn)\n",
    "        recomendations_dict[user] = coupon_id_rn\n",
    "\n",
    "    actual = []\n",
    "    pred = []\n",
    "    for k,_ in recomendations_dict.items():\n",
    "        actual.append(list(interactions_valid_dict[k]))\n",
    "        pred.append(list(recomendations_dict[k]))\n",
    "\n",
    "    mapk_l.append(mapk(actual,pred))\n",
    "\n",
    "print(np.mean(mapk_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep that number in mind, since we **ALWAYS** need to do better than that :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
